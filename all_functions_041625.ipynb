{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09716a72-4427-48f4-b453-309d2d005bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f42c141-2484-4911-9615-740cd12a8749",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a9e7787-4af9-472e-a936-6dc81dae5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to check that tail_base was also inside arm for a list of nose frames\n",
    "'''\n",
    "def check_tail_entry(df_mouse_boolean, list_of_frames, ti):\n",
    "    f=0; #tail entry frame, if valid\n",
    "    fc=0;\n",
    "    entered=False;\n",
    "    for l in list_of_frames:\n",
    "        if df_mouse_boolean.iloc[l,ti]==1:\n",
    "            f=l;\n",
    "            fc = fc+1;\n",
    "        if fc>5:\n",
    "            f = f-5;\n",
    "            entered= True;\n",
    "            break;\n",
    "    return entered, f;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47de0525-24d7-428d-aa38-dde18363a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to check when tail_base exited\n",
    "'''\n",
    "def check_tail_exit(df_mouse_boolean, startf, ti):\n",
    "    xf=0; #tail entry frame, if valid\n",
    "    fc=0;\n",
    "    end= False;\n",
    "    for l in range(startf, len(df_mouse_boolean)):\n",
    "        if df_mouse_boolean.iloc[l,ti]==0:\n",
    "            xf = l;\n",
    "            fc = fc+1;\n",
    "        else:\n",
    "            fc=0;\n",
    "        if fc>5:\n",
    "            xf=l-5;\n",
    "            break;\n",
    "    return xf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f0f3851-819b-437c-a374-667be90aac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to exclude repeat entries (when for a new nose entry, tail base is already inside arm)\n",
    "'''\n",
    "def check_repeat_entries(df_entries_stats_sorted):\n",
    "    df_valid_entries_stats_sorted= df_entries_stats_sorted.drop_duplicates(subset=['Tail Exit Frame'], keep='first')\n",
    "    return df_valid_entries_stats_sorted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcc8368d-a0c9-4efd-a4b4-fff68c628b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to get the max distance from center roi for a list of frames\n",
    "'''\n",
    "def get_max_dist(df_mouse_dist_roi, stf, enf,fi):\n",
    "    max = 0;\n",
    "    max_frame=0;\n",
    "    for frame in range(stf, (enf+1)):\n",
    "        temp = df_mouse_dist_roi.iloc[frame,fi];\n",
    "        if temp >= max:\n",
    "            max = temp;\n",
    "            max_frame=frame;\n",
    "    return max, max_frame;   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dffaa445-d0be-41bd-8c41-d336082b397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "main function will itirate through all frames for each nose inside arm X - from mouse_boolean.csv\n",
    "then call function to validate if entry is valid (tail is also entered for more than 5 frames) - returns True\n",
    "then once True, calculate entry latency - time for tail base to fully enter from nose sucessful entry\n",
    "then from the moment tail enters calculate duration - until tail leave\n",
    "calculate movement of nose and tail during the duration\n",
    "then calculate exit latency - time for tail base to fully exit from nose sucessful exit\n",
    "\n",
    "That will produce table as follows:\n",
    "    entry frame    exit frame    duration   nose mov nose velocity  tail mov  tail velocity   entry latency   exit latency  nose entry frame  nose exit frame (both for later directionality purposes)  \n",
    "A\n",
    "A\n",
    "A\n",
    "B\n",
    "B\n",
    "C\n",
    "C\n",
    "D\n",
    "D\n",
    "E\n",
    "E\n",
    "E\n",
    "'''\n",
    "def valid_entries_stats(df_mouse_boolean, df_mouse_dist_roi, mouse_id):\n",
    "    # 11 nose in A, 12 nose in B, ....\n",
    "    entries = [];\n",
    "    tail_entry_frame=[];\n",
    "    tail_exit_frame=[];\n",
    "    duration=[];\n",
    "    entry_latency=[];\n",
    "    exit_latency=[];\n",
    "    \n",
    "    nose_max_dist=[];\n",
    "    nose_max_dist_frame=[];\n",
    "    nose_max_dist_time=[];\n",
    "    \n",
    "    tail_base_max_dist=[];\n",
    "    tail_base_max_dist_frame=[];\n",
    "    tail_base_max_dist_time=[];\n",
    "    \n",
    "    nose_entry_frame=[];\n",
    "    nose_exit_frame=[];\n",
    "\n",
    "    arms = ['A', 'B', 'C', 'D', 'E']\n",
    "    \n",
    "    ina = df_mouse_boolean.columns.get_loc('Animal_1 nose inside polygon A (Boolean)')\n",
    "    ine = df_mouse_boolean.columns.get_loc('Animal_1 nose inside polygon E (Boolean)')\n",
    "    ita = df_mouse_boolean.columns.get_loc('Animal_1 tail_base inside polygon A (Boolean)')\n",
    "    dif = ita-ina\n",
    "\n",
    "    for i in range(ina,ine+1):\n",
    "        temp_ent = [];\n",
    "        for frame in range(0, (len(df_mouse_boolean)-1)):\n",
    "            if df_mouse_boolean.iloc[frame,i]==1:\n",
    "                temp_end = temp_ent.append(frame);\n",
    "            else:\n",
    "                if temp_ent: #if list is not empty\n",
    "                    valid, tail_entry = check_tail_entry(df_mouse_boolean, temp_ent, i+dif);\n",
    "                    if valid: # if tail_base is 1 for any\n",
    "                        entries.append(arms[i-ina])\n",
    "                        tail_entry_frame.append(tail_entry);\n",
    "                        tail_exit = check_tail_exit(df_mouse_boolean, temp_ent[-1], i+dif);\n",
    "                        tail_exit_frame.append(tail_exit);\n",
    "                        \n",
    "                        nose_entry_frame.append(temp_ent[0]);\n",
    "                        nose_exit_frame.append(temp_ent[-1]);\n",
    "                        \n",
    "                        ent_lat = (tail_entry-temp_ent[0])/30;\n",
    "                        ent_lat = ent_lat>=0 and ent_lat or 0\n",
    "                        entry_latency.append(ent_lat);            \n",
    "                        \n",
    "                        #dur =  (tail_exit-tail_entry+1)/30; #duration in s\n",
    "                        dur =  (temp_ent[-1]-tail_entry)/30; #duration in s \n",
    "                        duration.append(dur);\n",
    "                        \n",
    "                        ft = df_mouse_dist_roi.columns.get_loc('Animal_1 tail_base to Middle center distance (mm)')\n",
    "                        tail_base_max, tail_base_max_frame = get_max_dist(df_mouse_dist_roi, tail_entry, tail_exit,ft)\n",
    "                        tail_base_max_dist.append(tail_base_max)    \n",
    "                        tail_base_max_dist_frame.append(tail_base_max_frame)\n",
    "                        tmaxdur = (tail_base_max_frame-tail_entry)/30\n",
    "                        tail_base_max_dist_time.append(tmaxdur)\n",
    "                        \n",
    "                        \n",
    "                        fn = df_mouse_dist_roi.columns.get_loc('Animal_1 nose to Middle center distance (mm)')\n",
    "                        nose_max, nose_max_frame = get_max_dist(df_mouse_dist_roi, temp_ent[0], temp_ent[-1],fn)\n",
    "                        nose_max_dist.append(nose_max)    \n",
    "                        nose_max_dist_frame.append(nose_max_frame)\n",
    "                        nmaxdur = (nose_max_frame-temp_ent[0])/30\n",
    "                        nose_max_dist_time.append(nmaxdur)\n",
    "                                   \n",
    "                        exit_lat = (tail_exit-temp_ent[-1])/30;\n",
    "                        exit_lat = exit_lat>=0 and exit_lat or 0\n",
    "                        exit_latency.append(exit_lat);\n",
    "\n",
    "                    temp_ent = []; #reset for next entry vals\n",
    "\n",
    "        \n",
    "    valid_entries_stats ={'Arm Entry':entries, 'Tail Entry Frame':tail_entry_frame, 'Tail Exit Frame':tail_exit_frame, 'Duration':duration, \n",
    "                          'Entry Latency':entry_latency, 'Exit Latency':exit_latency, 'Nose Max Distance':nose_max_dist, \n",
    "                          'Nose Max Dist Frame':nose_max_dist_frame, 'Nose Time to Max Dist':nose_max_dist_time,\n",
    "                          'Tail Base Max Distance':tail_base_max_dist, 'Tail Base Max Dist Frame':tail_base_max_dist_frame,\n",
    "                          'Tail Base Time to Max Dist':tail_base_max_dist_time, 'Nose Entry Frame':nose_entry_frame, \n",
    "                          'Nose Exit Frame':nose_exit_frame}\n",
    "        \n",
    "    df_valid_entries_stats = pd.DataFrame(valid_entries_stats);\n",
    "    df_valid_entries_stats.to_csv(mouse_id+'_new_entry_stats.csv');\n",
    "    df_valid_entries_stats_s = df_valid_entries_stats.sort_values(by='Tail Entry Frame');\n",
    "    df_valid_entries_stats_sorted = check_repeat_entries(df_valid_entries_stats_s)\n",
    "    df_valid_entries_stats_sorted = df_valid_entries_stats_sorted.reset_index(drop=True);\n",
    "    df_valid_entries_stats_sorted.to_csv(mouse_id+'_new_entry_stats_sorted.csv');\n",
    "    return df_valid_entries_stats, df_valid_entries_stats_sorted;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bfbb124-01ff-442d-b195-20f03aa47615",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function just for the movement stats, \n",
    "entry frame and exit frame used for entry nose mov and vel and entry tail mov and vel\n",
    "'''\n",
    "def get_mov_stats(df_mouse_features, entry, exit, feature_i):\n",
    "    total_mov=0;\n",
    "    for m in df_mouse_features.iloc[entry:exit+1, feature_i]:\n",
    "        total_mov = total_mov+ m;\n",
    "    return total_mov;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96723f2a-94a0-4b65-9204-bbb60ab655ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function for tortuosity calculations\n",
    "get nose entry, max_dist and exit frame\n",
    "'entry' tortuosity as nose_mov/euclidean dist from nose entry coor to max_dist coor\n",
    "'exit' tortuosity as nose_mov/euclidean dist from max_dist coor to nose exit coor\n",
    "\n",
    "the euclidean dist is from the pythagorean theorem for the pair of coordinate points\n",
    "'''\n",
    "def get_tortuosity(df_mouse_features, frame1, frame2, i, pixel):\n",
    "    x1 = df_mouse_features['Nose_x'][frame1]\n",
    "    y1 = df_mouse_features['Nose_y'][frame1]\n",
    "    p1 = np.array((x1, y1))\n",
    "    x2 = df_mouse_features['Nose_x'][frame2]\n",
    "    y2 = df_mouse_features['Nose_y'][frame2]\n",
    "    p2 = np.array((x2, y2))\n",
    "    \n",
    "    L = get_mov_stats(df_mouse_features, frame1, frame2, i)\n",
    "    dist = np.linalg.norm(p2-p1)/pixel\n",
    "    tortuosity = L/dist\n",
    "    return tortuosity, L, dist;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f156181d-f097-415d-a4c5-e4690a1bc108",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to get frames in between and give back a list of coefficients for each arm\n",
    "'''\n",
    "def get_coeff(df_features, start, end):\n",
    "    a_count=0;\n",
    "    b_count=0;\n",
    "    c_count=0;\n",
    "    d_count=0;\n",
    "    e_count=0;\n",
    "    none_count=0;\n",
    "    for i in range(start, end+1):\n",
    "        none=0\n",
    "        if df_features.iloc[i, -5]:\n",
    "            a_count=a_count+1;\n",
    "        else:\n",
    "            none=none+1;\n",
    "        if df_features.iloc[i, -4]:\n",
    "            b_count=b_count+1;\n",
    "        else:\n",
    "            none=none+1;\n",
    "        if df_features.iloc[i, -3]:\n",
    "            c_count=c_count+1;\n",
    "        else:\n",
    "            none=none+1;        \n",
    "        if df_features.iloc[i, -2]:\n",
    "            d_count=d_count+1;\n",
    "        else:\n",
    "            none=none+1;            \n",
    "        if df_features.iloc[i, -1]:\n",
    "            e_count=e_count+1;\n",
    "        else:\n",
    "            none=none+1;\n",
    "        if none==5:\n",
    "            none_count=none_count+1;\n",
    "    tot = a_count+b_count+c_count+d_count+e_count+none_count;\n",
    "    a_coeff = a_count/tot;\n",
    "    b_coeff = b_count/tot;\n",
    "    c_coeff = c_count/tot;\n",
    "    d_coeff = d_count/tot;\n",
    "    e_coeff = e_count/tot;\n",
    "    return a_coeff, b_coeff, c_coeff, d_coeff, e_coeff;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bafe5323-b1f8-46c3-bb08-53351e69e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will itirate through all entries in order of nose exit frame\n",
    "call function to calculate time in the middle from nose exit to the next nose entry as duration in middle\n",
    "calculate movement and velocity for that as well\n",
    "and then call function to calculate directionality coefficients (from features csv) for those frames and return so that table is ordered as:\n",
    "\n",
    "    time duration in middle before entry   mov middle velocity middle direct coeff A   direct coeff B   direct coeff C   direct coeff D   direct coeff E\n",
    "A\n",
    "B\n",
    "D\n",
    "E\n",
    "C\n",
    "A\n",
    "D\n",
    "B\n",
    "E\n",
    "'''\n",
    "def all_other_stats(df_entries_sorted, df_mouse_features, mouse_id, pixel):\n",
    "    entries = df_entries_sorted['Arm Entry']\n",
    "    \n",
    "    arm_nose_movement=[];\n",
    "    arm_nose_velocity=[];\n",
    "    \n",
    "    entry_nose_tortuosity=[];\n",
    "    l_entry_nose_tortuosity=[]\n",
    "    dist_entry_nose_tortuosity=[]\n",
    "    exit_nose_tortuosity=[];\n",
    "    l_exit_nose_tortuosity=[]\n",
    "    dist_exit_nose_tortuosity=[]\n",
    "    #mean_nose_tortuosity=[];\n",
    "    other_tortuosity=[];\n",
    "    l_other_tortuosity=[];\n",
    "    dist_other_tortuosity=[]\n",
    "    arm_tail_movement=[];    \n",
    "    arm_tail_velocity=[];\n",
    "\n",
    "    middle_duration=[0]\n",
    "    middle_nose_movement=[0];\n",
    "    middle_nose_velocity=[0];\n",
    "    middle_tail_movement=[0];\n",
    "    middle_tail_velocity=[0];\n",
    "\n",
    "    entry_lat_nose_mov=[0]\n",
    "    entry_lat_nose_vel=[0]\n",
    "    entry_lat_tail_mov=[0]\n",
    "    entry_lat_tail_vel=[0]\n",
    "\n",
    "    exit_lat_nose_mov=[]\n",
    "    exit_lat_nose_vel=[]\n",
    "    exit_lat_tail_mov=[]\n",
    "    exit_lat_tail_vel=[]\n",
    "\n",
    "    tortuosity_center=[0]\n",
    "    l_center_tortuosity=[0]\n",
    "    dist_center_tortuosity=[0]\n",
    "\n",
    "    direct_coeff_A=[0];\n",
    "    direct_coeff_B=[0];\n",
    "    direct_coeff_C=[0];\n",
    "    direct_coeff_D=[0];\n",
    "    direct_coeff_E=[0];\n",
    "\n",
    "    new_direct_coeff_A=[0];\n",
    "    new_direct_coeff_B=[0];\n",
    "    new_direct_coeff_C=[0];\n",
    "    new_direct_coeff_D=[0];\n",
    "    new_direct_coeff_E=[0];\n",
    "\n",
    "    \n",
    "    for ent_i in range(0, len(df_entries_sorted)):\n",
    "        \n",
    "        #nose_arm_entry = df_entries_sorted.iloc[ent_i, 6];\n",
    "        nose_arm_entry = df_entries_sorted['Nose Entry Frame'][ent_i]\n",
    "        #nose_arm_exit = df_entries_sorted.iloc[ent_i, 7];\n",
    "        nose_arm_exit = df_entries_sorted['Nose Exit Frame'][ent_i]\n",
    "        tail_arm_entry = df_entries_sorted['Tail Entry Frame'][ent_i];\n",
    "        tail_arm_exit =  df_entries_sorted['Tail Exit Frame'][ent_i];\n",
    "        \n",
    "        n_feature_i = df_mouse_features.columns.get_loc('Movement_mouse_nose');\n",
    "\n",
    "        a_nose_mov = get_mov_stats(df_mouse_features, tail_arm_entry, nose_arm_exit, n_feature_i); \n",
    "        arm_nose_movement.append(a_nose_mov);\n",
    "        a_nose_vel = a_nose_mov/df_entries_sorted['Duration'][ent_i]; #divide movement by the duration\n",
    "        arm_nose_velocity.append(a_nose_vel);\n",
    "        \n",
    "        exl_nose_mov = get_mov_stats(df_mouse_features, nose_arm_exit, tail_arm_exit, n_feature_i)\n",
    "        exl_nose_mov = exl_nose_mov>=0 and exl_nose_mov or 0\n",
    "        exit_lat_nose_mov.append(exl_nose_mov)\n",
    "        exl_nose_vel = df_entries_sorted['Exit Latency'][ent_i] and exl_nose_mov/df_entries_sorted['Exit Latency'][ent_i] or 0;\n",
    "        exit_lat_nose_vel.append(exl_nose_vel)\n",
    "        \n",
    "        #arm_entry = df_entries_sorted.iloc[ent_i, 1];\n",
    "        #arm_entry = df_entries_sorted['Entry Frame'][ent_i]\n",
    "        #arm_exit = df_entries_sorted.iloc[ent_i, 2];\n",
    "        #arm_exit = df_entries_sorted['Exit Frame'][ent_i]\n",
    "\n",
    "        t_feature_i=df_mouse_features.columns.get_loc('Movement_mouse_tail_base');\n",
    "        \n",
    "        a_tail_mov = get_mov_stats(df_mouse_features, tail_arm_entry, nose_arm_exit, t_feature_i); \n",
    "        arm_tail_movement.append(a_tail_mov);\n",
    "        a_tail_vel = a_tail_mov/df_entries_sorted['Duration'][ent_i]; #divide movement by the duration\n",
    "        arm_tail_velocity.append(a_tail_vel);\n",
    "\n",
    "        exl_tail_mov = get_mov_stats(df_mouse_features, nose_arm_exit, tail_arm_exit, t_feature_i)\n",
    "        exl_tail_mov = exl_tail_mov>=0 and exl_tail_mov or 0\n",
    "        exit_lat_tail_mov.append(exl_tail_mov)\n",
    "        exl_tail_vel = df_entries_sorted['Exit Latency'][ent_i] and exl_tail_mov/df_entries_sorted['Exit Latency'][ent_i] or 0;\n",
    "        exit_lat_tail_vel.append(exl_tail_vel)\n",
    "\n",
    "        if ent_i>0:\n",
    "            enl_nose_mov = get_mov_stats(df_mouse_features, nose_arm_entry, tail_arm_entry, n_feature_i)\n",
    "            enl_nose_mov = enl_nose_mov>=0 and enl_nose_mov or 0\n",
    "            entry_lat_nose_mov.append(enl_nose_mov)\n",
    "            enl_nose_vel = df_entries_sorted['Entry Latency'][ent_i] and enl_nose_mov/df_entries_sorted['Entry Latency'][ent_i] or 0;\n",
    "            entry_lat_nose_vel.append(enl_nose_vel)\n",
    "            \n",
    "            enl_tail_mov = get_mov_stats(df_mouse_features, nose_arm_entry, tail_arm_entry, t_feature_i)\n",
    "            enl_tail_mov = enl_nose_mov>=0 and enl_tail_mov or 0\n",
    "            entry_lat_tail_mov.append(enl_tail_mov)\n",
    "            enl_tail_vel = df_entries_sorted['Entry Latency'][ent_i] and enl_tail_mov/df_entries_sorted['Entry Latency'][ent_i] or 0;\n",
    "            entry_lat_tail_vel.append(enl_tail_vel)\n",
    "            \n",
    "        fe = nose_arm_entry\n",
    "        fm = df_entries_sorted['Nose Max Dist Frame'][ent_i]\n",
    "        fx = nose_arm_exit\n",
    "        tortuosity_ent, le, diste = get_tortuosity(df_mouse_features, fe, fm, n_feature_i, pixel)\n",
    "        entry_nose_tortuosity.append(tortuosity_ent)\n",
    "        l_entry_nose_tortuosity.append(le)\n",
    "        dist_entry_nose_tortuosity.append(diste)\n",
    "        \n",
    "        tortuosity_ext, lx, distx = get_tortuosity(df_mouse_features, fm, fx, n_feature_i, pixel)\n",
    "        exit_nose_tortuosity.append(tortuosity_ext)\n",
    "        l_exit_nose_tortuosity.append(lx)\n",
    "        dist_exit_nose_tortuosity.append(distx)\n",
    "        \n",
    "        #mean_nose_tortuosity.append(np.mean([tortuosity_ent,tortuosity_ext])) \n",
    "        \n",
    "        ot, lot, distot =get_tortuosity(df_mouse_features, fe, fx, n_feature_i, pixel)\n",
    "        other_tortuosity.append(ot)\n",
    "        l_other_tortuosity.append(lot)\n",
    "        dist_other_tortuosity.append(distot)\n",
    "\n",
    "        \n",
    "        #now for all middle calculations, those always begin in ent2 (all the time between ent2 and ent1 - as video will always begin with mouse already in ent1)\n",
    "        # middle duration should be from moment that tail leaves arm to when nose enters arm, not encompassing neither exit nor entry latency\n",
    "        if ent_i!=0:\n",
    "            #n_start = df_entries_sorted.iloc[ent_i-1, 7];\n",
    "            #n_start = df_entries_sorted['Nose Exit Frame'][ent_i-1]\n",
    "            #n_end = nose_arm_entry;\n",
    "            #m_n_dur = (n_end-n_start+1)/30\n",
    "\n",
    "            m_start = df_entries_sorted['Tail Exit Frame'][ent_i-1]\n",
    "            m_end = df_entries_sorted['Nose Entry Frame'][ent_i]\n",
    "\n",
    "            m_dur = (m_end-m_start)/30\n",
    "            m_dur = m_dur>=0 and m_dur or 0;\n",
    "            middle_duration.append(m_dur);\n",
    "            \n",
    "            m_nose_mov = get_mov_stats(df_mouse_features, m_start, m_end, n_feature_i);\n",
    "            m_nose_mov = m_nose_mov>=0 and m_nose_mov or 0;\n",
    "            middle_nose_movement.append(m_nose_mov);\n",
    "            m_nose_vel = m_dur and m_nose_mov/m_dur or 0;\n",
    "            middle_nose_velocity.append(m_nose_vel);\n",
    "\n",
    "            #t_start = df_entries_sorted.iloc[ent_i-1, 2];\n",
    "            #t_start = df_entries_sorted['Exit Frame'][ent_i-1]\n",
    "            #t_end = tail_arm_entry;\n",
    "            #m_dur = (t_end-t_start+1)/30\n",
    "            \n",
    "            m_tail_mov = get_mov_stats(df_mouse_features, m_start, m_end, t_feature_i);\n",
    "            m_tail_mov = m_tail_mov>=0 and m_tail_mov or 0;\n",
    "            middle_tail_movement.append(m_tail_mov);\n",
    "            m_tail_vel = m_dur and m_tail_mov/m_dur or 0;\n",
    "            middle_tail_velocity.append(m_tail_vel);\n",
    "\n",
    "            n_start = df_entries_sorted['Nose Exit Frame'][ent_i-1]\n",
    "            t_end = tail_arm_entry\n",
    "            \n",
    "            \n",
    "            tc, lc, distc = get_tortuosity(df_mouse_features, n_start, m_end, n_feature_i, pixel)\n",
    "            tortuosity_center.append(tc)\n",
    "            l_center_tortuosity.append(lc)\n",
    "            dist_center_tortuosity.append(distc)\n",
    "            \n",
    "            ca, cb, cc, cd, ce = get_coeff(df_mouse_features, n_start, m_end);\n",
    "            \n",
    "            nca, ncb, ncc, ncd, nce = get_coeff(df_mouse_features, n_start, t_end);\n",
    "            \n",
    "            direct_coeff_A.append(ca);\n",
    "            direct_coeff_B.append(cb);\n",
    "            direct_coeff_C.append(cc);\n",
    "            direct_coeff_D.append(cd);\n",
    "            direct_coeff_E.append(ce);\n",
    "\n",
    "            new_direct_coeff_A.append(nca);\n",
    "            new_direct_coeff_B.append(ncb);\n",
    "            new_direct_coeff_C.append(ncc);\n",
    "            new_direct_coeff_D.append(ncd);\n",
    "            new_direct_coeff_E.append(nce);\n",
    "\n",
    "\n",
    "    \n",
    "    other_stats ={'Arm Entry':entries, 'Arm Nose Movement':arm_nose_movement, 'Arm Nose Velocity':arm_nose_velocity,\n",
    "                  'Arm Tail Movement':arm_tail_movement, 'Arm Tail Velocity':arm_tail_velocity,\n",
    "                  'Entry Tortuosity':entry_nose_tortuosity, 'L Entry Tortuosity':l_entry_nose_tortuosity, 'D Entry Tortuosity':dist_entry_nose_tortuosity,\n",
    "                  'Exit Tortuosity':exit_nose_tortuosity, 'L Exit Tortuosity':l_exit_nose_tortuosity, 'D Exit Tortuosity':dist_exit_nose_tortuosity,\n",
    "                  'Other Tortuosity':other_tortuosity, 'L Other Tortuosity':l_other_tortuosity, 'D Other Tortuosity':dist_other_tortuosity,\n",
    "                                                    \n",
    "                  'Entry Latency Nose Movement':entry_lat_nose_mov, 'Entry Latency Nose Velocity':entry_lat_nose_vel,\n",
    "                  'Entry Latency Tail Movement':entry_lat_tail_mov, 'Entry Latency Tail Velocity':entry_lat_tail_vel,\n",
    "                  \n",
    "                  'Middle Duration':middle_duration,\n",
    "                  'Middle Nose Movement':middle_nose_movement, 'Middle Nose Velocity':middle_nose_velocity, \n",
    "                  'Middle Tail Movement':middle_tail_movement, 'Middle Tail Velocity':middle_tail_velocity,\n",
    "                  \n",
    "                  'Exit Latency Nose Movement':exit_lat_nose_mov, 'Exit Latency Nose Velocity':exit_lat_nose_vel,\n",
    "                  'Exit Latency Tail Movement':exit_lat_tail_mov, 'Exit Latency Tail Velocity':exit_lat_tail_vel,\n",
    "                  \n",
    "                  'Middle Tortuosity':tortuosity_center, 'L Middle Tortuosity':l_center_tortuosity, 'D Middle Tortuosity':dist_center_tortuosity,\n",
    "                  \n",
    "                  'Directionality Coefficiet A':direct_coeff_A, 'Directionality Coefficiet B':direct_coeff_B, \n",
    "                  'Directionality Coefficiet C':direct_coeff_C, 'Directionality Coefficiet D':direct_coeff_D, \n",
    "                  'Directionality Coefficiet E':direct_coeff_E,\n",
    "                  'New Directionality Coefficiet A':new_direct_coeff_A, 'New Directionality Coefficiet B':new_direct_coeff_B, \n",
    "                  'New Directionality Coefficiet C':new_direct_coeff_C, 'New Directionality Coefficiet D':new_direct_coeff_D, \n",
    "                  'New Directionality Coefficiet E':new_direct_coeff_E\n",
    "                 }\n",
    "    df_other_stats = pd.DataFrame(other_stats);\n",
    "    df_other_stats = df_other_stats.reset_index(drop=True);\n",
    "    df_other_stats.to_csv(mouse_id+'_newest_other_stats.csv');\n",
    "    return df_other_stats;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cad671f-bba0-41bc-a282-ade7f88f17e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will just get the coefficients of the current arm entered and the past two so in ABC at C look at coeff for C and coeff for A\n",
    "    current coeff  skip arm coeff   current coeff time proportional   skip arm coeff time proportional\n",
    "A    value for A     value for none\n",
    "B    value for B     value for none\n",
    "C    value for C    value for A\n",
    "D    value for D    value for B\n",
    "E    value for E    value for C\n",
    "A\n",
    "C\n",
    "'''\n",
    "def add_lag_dir_coefficients(df_other_stats, df_entries_sorted, mouse_id):\n",
    "    entries = df_other_stats.iloc[:,0];\n",
    "    \n",
    "    cur_coeff=[0];\n",
    "    lag_1_cur_coeff=[0,0];\n",
    "    lag_2_cur_coeff=[0,0,0];\n",
    "    lag_3_cur_coeff=[0,0,0,0];\n",
    "    lag_4_cur_coeff=[0,0,0,0,0];\n",
    "\n",
    "    new_cur_coeff=[0];\n",
    "    new_lag_1_cur_coeff=[0,0];\n",
    "    new_lag_2_cur_coeff=[0,0,0];\n",
    "    new_lag_3_cur_coeff=[0,0,0,0];\n",
    "    new_lag_4_cur_coeff=[0,0,0,0,0];\n",
    "    \n",
    "    #lag_2_coeff=[0]; \n",
    "    \n",
    "    cur_coeff_time=[0];\n",
    "    lag_1_cur_coeff_time=[0,0];\n",
    "    lag_2_cur_coeff_time=[0,0,0];\n",
    "    lag_3_cur_coeff_time=[0,0,0,0];\n",
    "    lag_4_cur_coeff_time=[0,0,0,0,0];\n",
    "    #lag_2_coeff_time=[0];\n",
    "\n",
    "    new_cur_coeff_time=[0];\n",
    "    new_lag_1_cur_coeff_time=[0,0];\n",
    "    new_lag_2_cur_coeff_time=[0,0,0];\n",
    "    new_lag_3_cur_coeff_time=[0,0,0,0];\n",
    "    new_lag_4_cur_coeff_time=[0,0,0,0,0];\n",
    "\n",
    "    for i in range(1, len(df_other_stats)):\n",
    "        \n",
    "        arms = ['A', 'B', 'C', 'D', 'E']\n",
    "        \n",
    "        li = arms.index(df_other_stats['Arm Entry'][i])\n",
    "\n",
    "        indcs = df_other_stats.columns.get_loc('Directionality Coefficiet A')\n",
    "        indnewcs = df_other_stats.columns.get_loc('New Directionality Coefficiet A')\n",
    "        \n",
    "        '''\n",
    "        let = df_other_stats['Arm Entry'][i]        \n",
    "        \n",
    "        if let=='E':\n",
    "            ind=-1\n",
    "        elif let=='D':\n",
    "            ind=-2\n",
    "        elif let=='C':\n",
    "            ind=-3\n",
    "        elif let=='B':\n",
    "            ind=-4\n",
    "        elif let=='A':\n",
    "            ind=-5\n",
    "        '''\n",
    "        c = df_other_stats.iloc[i,indcs+li]\n",
    "        cur_coeff.append(c)\n",
    "        tc = c*(df_other_stats['Middle Duration'][i]+df_entries_sorted['Exit Latency'][i-1])\n",
    "        cur_coeff_time.append(tc)\n",
    "        \n",
    "        nc = df_other_stats.iloc[i,indnewcs+li]\n",
    "        new_cur_coeff.append(nc)\n",
    "        ntc = nc*(df_other_stats['Middle Duration'][i]+df_entries_sorted['Exit Latency'][i-1]+df_entries_sorted['Entry Latency'][i])\n",
    "        new_cur_coeff_time.append(ntc)         \n",
    "        \n",
    "        if i > 4:\n",
    "            c = df_other_stats.iloc[i-4,indcs+li]\n",
    "            lag_4_cur_coeff.append(c)\n",
    "            tc = c*(df_other_stats['Middle Duration'][i-4]+df_entries_sorted['Exit Latency'][i-5])\n",
    "            lag_4_cur_coeff_time.append(tc)           \n",
    "        \n",
    "            nc = df_other_stats.iloc[i-4,indnewcs+li]\n",
    "            new_lag_4_cur_coeff.append(nc)\n",
    "            ntc = nc*(df_other_stats['Middle Duration'][i-4]+df_entries_sorted['Exit Latency'][i-5]+df_entries_sorted['Entry Latency'][i-4])\n",
    "            new_lag_4_cur_coeff_time.append(ntc)         \n",
    "            \n",
    "        if i > 3:\n",
    "            c = df_other_stats.iloc[i-3,indcs+li]\n",
    "            lag_3_cur_coeff.append(c)\n",
    "            tc = c*(df_other_stats['Middle Duration'][i-3]+df_entries_sorted['Exit Latency'][i-4])\n",
    "            lag_3_cur_coeff_time.append(tc)\n",
    "\n",
    "            nc = df_other_stats.iloc[i-3,indnewcs+li]\n",
    "            new_lag_3_cur_coeff.append(nc)\n",
    "            ntc = nc*(df_other_stats['Middle Duration'][i-3]+df_entries_sorted['Exit Latency'][i-4]+df_entries_sorted['Entry Latency'][i-3])\n",
    "            new_lag_3_cur_coeff_time.append(ntc)\n",
    "        \n",
    "        if i > 2:\n",
    "            c = df_other_stats.iloc[i-2,indcs+li]\n",
    "            lag_2_cur_coeff.append(c)\n",
    "            tc = c*(df_other_stats['Middle Duration'][i-2]+df_entries_sorted['Exit Latency'][i-3])\n",
    "            lag_2_cur_coeff_time.append(tc)\n",
    "        \n",
    "            nc = df_other_stats.iloc[i-2,indnewcs+li]\n",
    "            new_lag_2_cur_coeff.append(nc)\n",
    "            ntc = nc*(df_other_stats['Middle Duration'][i-2]+df_entries_sorted['Exit Latency'][i-3]+df_entries_sorted['Entry Latency'][i-2])\n",
    "            new_lag_2_cur_coeff_time.append(ntc)        \n",
    "        \n",
    "        if i > 1:\n",
    "            c = df_other_stats.iloc[i-1,indcs+li]\n",
    "            lag_1_cur_coeff.append(c)\n",
    "            tc = c*(df_other_stats['Middle Duration'][i-1]+df_entries_sorted['Exit Latency'][i-2])\n",
    "            lag_1_cur_coeff_time.append(tc)\n",
    "        \n",
    "            nc = df_other_stats.iloc[i-1,indnewcs+li]\n",
    "            new_lag_1_cur_coeff.append(nc)\n",
    "            ntc = nc*(df_other_stats['Middle Duration'][i-1]+df_entries_sorted['Exit Latency'][i-2]+df_entries_sorted['Entry Latency'][i-1])\n",
    "            new_lag_1_cur_coeff_time.append(ntc)   \n",
    "    \n",
    "    lagged_coeff ={'Arm Entry':entries, 'Current Coeff':cur_coeff, 'Lagged 1 Cur Coeff':lag_1_cur_coeff, 'Lagged 2 Cur Coeff':lag_2_cur_coeff,\n",
    "                   'Lagged 3 Cur Coeff':lag_3_cur_coeff, 'Lagged 4 Cur Coeff':lag_4_cur_coeff,\n",
    "                   'Current Coeff Time Proportional':cur_coeff_time, 'Lagged 1 Cur Coeff Time Proportional':lag_1_cur_coeff_time,\n",
    "                   'Lagged 2 Cur Coeff Time Proportional':lag_2_cur_coeff_time, 'Lagged 3 Cur Coeff Time Proportional':lag_3_cur_coeff_time,\n",
    "                   'Lagged 4 Cur Coeff Time Proportional':lag_4_cur_coeff_time,\n",
    "\n",
    "                   'New Current Coeff':new_cur_coeff, 'New Lagged 1 Cur Coeff':new_lag_1_cur_coeff, 'New Lagged 2 Cur Coeff':new_lag_2_cur_coeff,\n",
    "                   'New Lagged 3 Cur Coeff':new_lag_3_cur_coeff, 'New Lagged 4 Cur Coeff':new_lag_4_cur_coeff,\n",
    "                   'New Current Coeff Time Proportional':new_cur_coeff_time, 'New Lagged 1 Cur Coeff Time Proportional':new_lag_1_cur_coeff_time,\n",
    "                   'New Lagged 2 Cur Coeff Time Proportional':new_lag_2_cur_coeff_time, 'New Lagged 3 Cur Coeff Time Proportional':new_lag_3_cur_coeff_time,\n",
    "                   'New Lagged 4 Cur Coeff Time Proportional':new_lag_4_cur_coeff_time\n",
    "                  }\n",
    "    \n",
    "    df_lagged_coeff = pd.DataFrame(lagged_coeff);\n",
    "    df_lagged_coeff = df_lagged_coeff.reset_index(drop=True);\n",
    "    df_lagged_coeff.to_csv(mouse_id+'_newest_lagged_coeff.csv');\n",
    "    return df_lagged_coeff;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c61fab70-24fd-445e-8875-1e9cd38e1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(args):\n",
    "    '''\n",
    "    function checks whether list of arguments are unique\n",
    "    returns boolean\n",
    "    '''\n",
    "    sequence=[];\n",
    "    for arg in args:\n",
    "        sequence.append(arg.lower());\n",
    "    isunique = len(sequence)==len(set(sequence)) # set() removes repetitions\n",
    "    return isunique #True for unique sequence, False if repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15ac5ad2-fe03-4f5b-9458-2a448c946f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will be to return output\n",
    "'''\n",
    "def get_output(*args):\n",
    "    for i in range(len(args)-1):\n",
    "        output = len(args);\n",
    "        if check_args(args[i:]):\n",
    "            output = output-i;\n",
    "            break;\n",
    "        else:\n",
    "            output = 1;\n",
    "    return output;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa34aa8f-75f8-421c-8eda-70763f2d77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will add mouse turns for any possible turn direction and performance interactions\n",
    "'''\n",
    "def get_turn(*args):\n",
    "    list  = ['A', 'B', 'C', 'D', 'E', 'A' , 'B', 'C', 'D', 'E']\n",
    "    i1 = list.index(args[0])\n",
    "    for i in range(i1, len(list)):\n",
    "        if list[i]==args[1]:\n",
    "            i2 = i;\n",
    "            break;\n",
    "    t =  i2-i1;\n",
    "    turns = ['N', '1L', '2L', '2R', '1R', 'N']\n",
    "    turn = turns[t]\n",
    "    return turn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5430dc8-514b-4103-876d-b59cf701ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "this function will set ouput as the choice level (5,4,3,2, and 1)\n",
    "A   1      \n",
    "B   2 \n",
    "D   3\n",
    "E   4\n",
    "C   5\n",
    "A   5\n",
    "D   4\n",
    "B   5\n",
    "E   5\n",
    "and will finally create all info needed for the next step - classifier\n",
    "'''\n",
    "def add_choice_output(df_entry_stats_ordered, df_other_stats, df_lagged_coeff, mouse_id):\n",
    "    entries = df_entry_stats_ordered['Arm Entry'];\n",
    "\n",
    "    choice_output=[1];\n",
    "   \n",
    "    p_exitmid_1 = [0]\n",
    "    p_midentry_1 = [0]\n",
    "    p_exitmidentry_1 = [0]\n",
    "\n",
    "   \n",
    "    for ind in range(1, len(entries)):\n",
    "\n",
    "        p_exitmid_1.append(np.sum([df_entry_stats_ordered['Exit Latency'][ind-1],df_other_stats['Middle Duration'][ind]])); \n",
    "        p_midentry_1.append(np.sum([df_other_stats['Middle Duration'][ind], df_entry_stats_ordered['Entry Latency'][ind]]));\n",
    "        p_exitmidentry_1.append(np.sum([df_entry_stats_ordered['Exit Latency'][ind-1],df_other_stats['Middle Duration'][ind], df_entry_stats_ordered['Entry Latency'][ind]]));\n",
    "        \n",
    "        ent1 = df_entry_stats_ordered.iloc[ind-4,0]\n",
    "        ent2 = df_entry_stats_ordered.iloc[ind-3,0]\n",
    "        ent3 = df_entry_stats_ordered.iloc[ind-2,0]\n",
    "        ent4 = df_entry_stats_ordered.iloc[ind-1,0]\n",
    "        ent5 = df_entry_stats_ordered.iloc[ind,0]\n",
    "\n",
    "        if ind > 3:\n",
    "            temp_output = get_output(ent1, ent2, ent3, ent4, ent5)\n",
    "            choice_output.append(temp_output);\n",
    "        elif ind > 2:\n",
    "            temp_output = get_output(ent2, ent3, ent4, ent5)\n",
    "            choice_output.append(temp_output);        \n",
    "        elif ind >1:\n",
    "            temp_output = get_output(ent3, ent4, ent5)\n",
    "            choice_output.append(temp_output);\n",
    "        elif ind >0:\n",
    "            temp_output = get_output(ent4, ent5)\n",
    "            choice_output.append(temp_output);\n",
    "    \n",
    "    turn = ['N'];\n",
    "    for i in range(1, len(entries)):\n",
    "        temp_turn = get_turn(entries[i-1],entries[i])\n",
    "        turn.append(temp_turn);\n",
    "\n",
    "    df_everything_stats = df_entry_stats_ordered.drop(columns = ['Tail Entry Frame', 'Tail Exit Frame', 'Duration', 'Entry Latency', 'Exit Latency',\n",
    "                                                                 'Nose Max Distance', 'Nose Time to Max Dist', 'Tail Base Max Distance', 'Tail Base Time to Max Dist',\n",
    "                                                                 'Nose Entry Frame', 'Nose Exit Frame', 'Nose Max Dist Frame', 'Tail Base Max Dist Frame'])\n",
    "\n",
    "    #df_everything_stats = df_entry_stats_ordered['Arm Entry']\n",
    "    \n",
    "    df_everything_stats['Middle Duration'] = df_other_stats['Middle Duration']\n",
    "    df_everything_stats['Middle Nose Movement'] = df_other_stats['Middle Nose Movement']\n",
    "    df_everything_stats['Middle Nose Velocity'] = df_other_stats['Middle Nose Velocity']\n",
    "    df_everything_stats['Middle Tail Movement'] = df_other_stats['Middle Tail Movement']\n",
    "    df_everything_stats['Middle Tail Velocity'] = df_other_stats['Middle Tail Velocity']\n",
    "    \n",
    "    df_everything_stats['Middle Tortuosity'] = df_other_stats['Middle Tortuosity']\n",
    "\n",
    "    df_everything_stats['Current Coeff'] = df_lagged_coeff['Current Coeff']\n",
    "    df_everything_stats['Lagged 1 Cur Coeff'] = df_lagged_coeff['Lagged 1 Cur Coeff']\n",
    "    df_everything_stats['Lagged 2 Cur Coeff'] = df_lagged_coeff['Lagged 2 Cur Coeff']\n",
    "    df_everything_stats['Lagged 3 Cur Coeff'] = df_lagged_coeff['Lagged 3 Cur Coeff']\n",
    "    df_everything_stats['Lagged 4 Cur Coeff'] = df_lagged_coeff['Lagged 4 Cur Coeff']\n",
    "\n",
    "    df_everything_stats['New Current Coeff'] = df_lagged_coeff['New Current Coeff']\n",
    "    df_everything_stats['New Lagged 1 Cur Coeff'] = df_lagged_coeff['New Lagged 1 Cur Coeff']\n",
    "    df_everything_stats['New Lagged 2 Cur Coeff'] = df_lagged_coeff['New Lagged 2 Cur Coeff']\n",
    "    df_everything_stats['New Lagged 3 Cur Coeff'] = df_lagged_coeff['New Lagged 3 Cur Coeff']\n",
    "    df_everything_stats['New Lagged 4 Cur Coeff'] = df_lagged_coeff['New Lagged 4 Cur Coeff']    \n",
    "    \n",
    "    df_everything_stats['Current Coeff Time Proportional'] = df_lagged_coeff['Current Coeff Time Proportional']\n",
    "    df_everything_stats['Lagged 1 Cur Coeff Time Proportional'] = df_lagged_coeff['Lagged 1 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['Lagged 2 Cur Coeff Time Proportional'] = df_lagged_coeff['Lagged 2 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['Lagged 3 Cur Coeff Time Proportional'] = df_lagged_coeff['Lagged 3 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['Lagged 4 Cur Coeff Time Proportional'] = df_lagged_coeff['Lagged 4 Cur Coeff Time Proportional']\n",
    "\n",
    "    df_everything_stats['New Current Coeff Time Proportional'] = df_lagged_coeff['New Current Coeff Time Proportional']\n",
    "    df_everything_stats['New Lagged 1 Cur Coeff Time Proportional'] = df_lagged_coeff['New Lagged 1 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['New Lagged 2 Cur Coeff Time Proportional'] = df_lagged_coeff['New Lagged 2 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['New Lagged 3 Cur Coeff Time Proportional'] = df_lagged_coeff['New Lagged 3 Cur Coeff Time Proportional']\n",
    "    df_everything_stats['New Lagged 4 Cur Coeff Time Proportional'] = df_lagged_coeff['New Lagged 4 Cur Coeff Time Proportional']\n",
    "\n",
    "    df_everything_stats['Entry Latency'] = df_entry_stats_ordered['Entry Latency']\n",
    "    df_everything_stats['Entry Latency Nose Movement'] = df_other_stats['Entry Latency Nose Movement']\n",
    "    df_everything_stats['Entry Latency Nose Velocity'] = df_other_stats['Entry Latency Nose Velocity']\n",
    "    df_everything_stats['Entry Latency Tail Movement'] = df_other_stats['Entry Latency Tail Movement']\n",
    "    df_everything_stats['Entry Latency Tail Velocity'] = df_other_stats['Entry Latency Tail Velocity']\n",
    "\n",
    "    df_everything_stats['Duration'] = df_entry_stats_ordered['Duration']\n",
    "    df_everything_stats['Nose Max Distance'] = df_entry_stats_ordered['Nose Max Distance']\n",
    "    df_everything_stats['Nose Time to Max Dist'] = df_entry_stats_ordered['Nose Time to Max Dist']\n",
    "    \n",
    "    df_everything_stats['Tail Base Max Distance'] = df_entry_stats_ordered['Tail Base Max Distance']\n",
    "    df_everything_stats['Tail Base Time to Max Dist'] = df_entry_stats_ordered['Tail Base Time to Max Dist']\n",
    "\n",
    "    df_everything_stats['Arm Nose Movement'] = df_other_stats['Arm Nose Movement']\n",
    "    df_everything_stats['Arm Nose Velocity'] = df_other_stats['Arm Nose Velocity']\n",
    "    df_everything_stats['Arm Tail Movement'] = df_other_stats['Arm Tail Movement']\n",
    "    df_everything_stats['Arm Tail Velocity'] = df_other_stats['Arm Tail Velocity']\n",
    "\n",
    "    df_everything_stats['Entry Tortuosity'] = df_other_stats['Entry Tortuosity']\n",
    "    df_everything_stats['Exit Tortuosity'] = df_other_stats['Exit Tortuosity']\n",
    "    df_everything_stats['Other Tortuosity'] = df_other_stats['Other Tortuosity']\n",
    "\n",
    "    df_everything_stats['Exit Latency'] = df_entry_stats_ordered['Exit Latency']\n",
    "    df_everything_stats['Exit Latency Nose Movement'] = df_other_stats['Exit Latency Nose Movement']\n",
    "    df_everything_stats['Exit Latency Nose Velocity'] = df_other_stats['Exit Latency Nose Velocity']\n",
    "    df_everything_stats['Exit Latency Tail Movement'] = df_other_stats['Exit Latency Tail Movement']\n",
    "    df_everything_stats['Exit Latency Tail Velocity'] = df_other_stats['Exit Latency Tail Velocity']\n",
    "\n",
    "    df_everything_stats['ExitMid Duration'] = p_exitmid_1\n",
    "    df_everything_stats['MidEntry Duration'] = p_midentry_1\n",
    "    df_everything_stats['ExitMidEntry Duration'] = p_exitmidentry_1\n",
    "    \n",
    "    df_everything_stats['Turn'] = turn\n",
    "    df_everything_stats['Choice Output'] = choice_output\n",
    "    df_everything_stats = df_everything_stats.reset_index(drop=True);    \n",
    "    df_everything_stats.to_csv(mouse_id+'_newest_everything_stats.csv');    \n",
    "\n",
    "    return df_everything_stats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b831381-d54e-4314-aea7-a7d97bf4ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function that gets df and uses minmaxscaler, then returns scaled df and saves it to csv\n",
    "'''\n",
    "def scale_it(df_everything_stats, mouse_id):\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    minmaxsc =  MinMaxScaler(copy=True, clip=False)\n",
    "    mm_df = df_everything_stats.copy()\n",
    "    mm_df[mm_df.columns[1:-2]] = minmaxsc.fit_transform(df_everything_stats[df_everything_stats.columns[1:-2]])\n",
    "\n",
    "    mm_df.to_csv(mouse_id+'_newest_mm_everything_stats.csv');\n",
    "    return mm_df;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30850ffd-e78b-45ad-83cb-484a6f5be2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "function to create the lagging for all previous 4 choices\n",
    "'''\n",
    "def lagging_four_prev_choices(df_pls, mouse_id):\n",
    "    lagged_df_everything_stats = df_pls.select(\n",
    "    \n",
    "    \"Middle Duration\", \n",
    "    *[pl.col(\"Middle Duration\").shift(i).alias(f\"lagged_{i}_mid_duration\") for i in [1,2,3,4]],\n",
    "    \"Middle Nose Movement\", \n",
    "    *[pl.col(\"Middle Nose Movement\").shift(i).alias(f\"lagged_{i}_mid_nose_mov\") for i in [1,2,3,4]],\n",
    "    \"Middle Nose Velocity\", \n",
    "    *[pl.col(\"Middle Nose Velocity\").shift(i).alias(f\"lagged_{i}_mid_nose_vel\") for i in [1,2,3,4]],\n",
    "    \"Middle Tail Movement\", \n",
    "    *[pl.col(\"Middle Tail Movement\").shift(i).alias(f\"lagged_{i}_mid_tail_mov\") for i in [1,2,3,4]],\n",
    "    \"Middle Tail Velocity\", \n",
    "    *[pl.col(\"Middle Tail Velocity\").shift(i).alias(f\"lagged_{i}_mid_tail_vel\") for i in [1,2,3,4]],       \n",
    "        \n",
    "    \"Middle Tortuosity\", \n",
    "    *[pl.col(\"Middle Tortuosity\").shift(i).alias(f\"lagged_{i}_mid_tortuosity\") for i in [1,2,3,4]],          \n",
    "    \n",
    "    \"Current Coeff\", \n",
    "    *[pl.col(\"Current Coeff\").shift(i).alias(f\"lagged_{i}_current_coeff\") for i in [1,2,3,4]],   \n",
    "    \"Lagged 1 Cur Coeff\", \n",
    "    *[pl.col(\"Lagged 1 Cur Coeff\").shift(i).alias(f\"lagged_{i}_lagged_1_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"Lagged 2 Cur Coeff\", \n",
    "    *[pl.col(\"Lagged 2 Cur Coeff\").shift(i).alias(f\"lagged_{i}_lagged_2_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"Lagged 3 Cur Coeff\", \n",
    "    *[pl.col(\"Lagged 3 Cur Coeff\").shift(i).alias(f\"lagged_{i}_lagged_3_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"Lagged 4 Cur Coeff\", \n",
    "    *[pl.col(\"Lagged 4 Cur Coeff\").shift(i).alias(f\"lagged_{i}_lagged_4_cur_coeff\") for i in [1,2,3,4]],\n",
    "\n",
    "    \"New Current Coeff\", \n",
    "    *[pl.col(\"New Current Coeff\").shift(i).alias(f\"lagged_{i}_new_current_coeff\") for i in [1,2,3,4]],   \n",
    "    \"New Lagged 1 Cur Coeff\", \n",
    "    *[pl.col(\"New Lagged 1 Cur Coeff\").shift(i).alias(f\"lagged_{i}_new_lagged_1_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 2 Cur Coeff\", \n",
    "    *[pl.col(\"New Lagged 2 Cur Coeff\").shift(i).alias(f\"lagged_{i}_new_lagged_2_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 3 Cur Coeff\", \n",
    "    *[pl.col(\"New Lagged 3 Cur Coeff\").shift(i).alias(f\"lagged_{i}_new_lagged_3_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 4 Cur Coeff\", \n",
    "    *[pl.col(\"New Lagged 4 Cur Coeff\").shift(i).alias(f\"lagged_{i}_new_lagged_4_cur_coeff\") for i in [1,2,3,4]],\n",
    "    \n",
    "    \"Current Coeff Time Proportional\", \n",
    "    *[pl.col(\"Current Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_current_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"Lagged 1 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"Lagged 1 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_lagged_1_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"Lagged 2 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"Lagged 2 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_lagged_2_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"Lagged 3 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"Lagged 3 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_lagged_3_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"Lagged 4 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"Lagged 4 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_lagged_4_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "\n",
    "    \"New Current Coeff Time Proportional\", \n",
    "    *[pl.col(\"New Current Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_new_current_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 1 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"New Lagged 1 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_new_lagged_1_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 2 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"New Lagged 2 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_new_lagged_2_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 3 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"New Lagged 3 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_new_lagged_3_cur_coeff_time_prop\") for i in [1,2,3,4]],\n",
    "    \"New Lagged 4 Cur Coeff Time Proportional\", \n",
    "    *[pl.col(\"New Lagged 4 Cur Coeff Time Proportional\").shift(i).alias(f\"lagged_{i}_new_lagged_4_cur_coeff_time_prop\") for i in [1,2,3,4]],    \n",
    "    \n",
    "    \"Entry Latency\", \n",
    "    *[pl.col(\"Entry Latency\").shift(i).alias(f\"lagged_{i}_entry_lat\") for i in [1,2,3,4]],\n",
    "    \"Entry Latency Nose Movement\", \n",
    "    *[pl.col(\"Entry Latency Nose Movement\").shift(i).alias(f\"lagged_{i}_entry_lat_nose_mov\") for i in [1,2,3,4]],\n",
    "    \"Entry Latency Nose Velocity\", \n",
    "    *[pl.col(\"Entry Latency Nose Velocity\").shift(i).alias(f\"lagged_{i}_entry_lat_nose_vel\") for i in [1,2,3,4]],\n",
    "    \"Entry Latency Tail Movement\", \n",
    "    *[pl.col(\"Entry Latency Tail Movement\").shift(i).alias(f\"lagged_{i}_entry_lat_tail_mov\") for i in [1,2,3,4]],\n",
    "    \"Entry Latency Tail Velocity\", \n",
    "    *[pl.col(\"Entry Latency Tail Velocity\").shift(i).alias(f\"lagged_{i}_entry_lat_tail_vel\") for i in [1,2,3,4]],   \n",
    " \n",
    "    \"Duration\", \n",
    "    *[pl.col(\"Duration\").shift(i).alias(f\"lagged_{i}_duration\") for i in [1,2,3,4]],\n",
    "    \"Nose Max Distance\",\n",
    "    *[pl.col(\"Nose Max Distance\").shift(i).alias(f\"lagged_{i}_nose_max_distance\") for i in [1,2,3,4]],    \n",
    "    \"Nose Time to Max Dist\",\n",
    "    *[pl.col(\"Nose Time to Max Dist\").shift(i).alias(f\"lagged_{i}_nose_time_to_max_dist\") for i in [1,2,3,4]],        \n",
    "    \"Tail Base Max Distance\",\n",
    "    *[pl.col(\"Tail Base Max Distance\").shift(i).alias(f\"lagged_{i}_tail_max_distance\") for i in [1,2,3,4]],    \n",
    "    \"Tail Base Time to Max Dist\",\n",
    "    *[pl.col(\"Tail Base Time to Max Dist\").shift(i).alias(f\"lagged_{i}_tail_time_to_max_dist\") for i in [1,2,3,4]],       \n",
    "    \"Arm Nose Movement\", \n",
    "    *[pl.col(\"Arm Nose Movement\").shift(i).alias(f\"lagged_{i}_arm_nose_mov\") for i in [1,2,3,4]],\n",
    "    \"Arm Nose Velocity\", \n",
    "    *[pl.col(\"Arm Nose Velocity\").shift(i).alias(f\"lagged_{i}_arm_nose_vel\") for i in [1,2,3,4]],\n",
    "    \"Arm Tail Movement\", \n",
    "    *[pl.col(\"Arm Tail Movement\").shift(i).alias(f\"lagged_{i}_arm_tail_mov\") for i in [1,2,3,4]],\n",
    "    \"Arm Tail Velocity\", \n",
    "    *[pl.col(\"Arm Tail Velocity\").shift(i).alias(f\"lagged_{i}_arm_tail_vel\") for i in [1,2,3,4]],\n",
    "    \"Entry Tortuosity\",\n",
    "    *[pl.col(\"Entry Tortuosity\").shift(i).alias(f\"lagged_{i}_entry_tortuosity\") for i in [1,2,3,4]],       \n",
    "    \"Exit Tortuosity\",\n",
    "    *[pl.col(\"Exit Tortuosity\").shift(i).alias(f\"lagged_{i}_exit_tortuosity\") for i in [1,2,3,4]],    \n",
    "    \"Other Tortuosity\",\n",
    "    *[pl.col(\"Other Tortuosity\").shift(i).alias(f\"lagged_{i}_other_tortuosity\") for i in [1,2,3,4]],    \n",
    "\n",
    "    \"Exit Latency\", \n",
    "    *[pl.col(\"Exit Latency\").shift(i).alias(f\"lagged_{i}_exit_lat\") for i in [1,2,3,4]], \n",
    "    \"Exit Latency Nose Movement\", \n",
    "    *[pl.col(\"Exit Latency Nose Movement\").shift(i).alias(f\"lagged_{i}_exit_lat_nose_mov\") for i in [1,2,3,4]],\n",
    "    \"Exit Latency Nose Velocity\", \n",
    "    *[pl.col(\"Exit Latency Nose Velocity\").shift(i).alias(f\"lagged_{i}_exit_lat_nose_vel\") for i in [1,2,3,4]],\n",
    "    \"Exit Latency Tail Movement\", \n",
    "    *[pl.col(\"Exit Latency Tail Movement\").shift(i).alias(f\"lagged_{i}_exit_lat_tail_mov\") for i in [1,2,3,4]],\n",
    "    \"Exit Latency Tail Velocity\", \n",
    "    *[pl.col(\"Exit Latency Tail Velocity\").shift(i).alias(f\"lagged_{i}_exit_lat_tail_vel\") for i in [1,2,3,4]],   \n",
    "\n",
    "    \"ExitMid Duration\",\n",
    "    *[pl.col(\"ExitMid Duration\").shift(i).alias(f\"lagged_{i}_exitmid_duration\") for i in [1,2,3,4]],\n",
    "    \"MidEntry Duration\", \n",
    "    *[pl.col(\"MidEntry Duration\").shift(i).alias(f\"lagged_{i}_midentry_duration\") for i in [1,2,3,4]],\n",
    "    \"ExitMidEntry Duration\",\n",
    "    *[pl.col(\"ExitMidEntry Duration\").shift(i).alias(f\"lagged_{i}_exitmidentry_duration\") for i in [1,2,3,4]],\n",
    "    \n",
    "    \"Turn\",\n",
    "    *[pl.col(\"Turn\").shift(i).alias(f\"lagged_{i}_turn_ago\") for i in [1,2,3,4]],\n",
    "    \"Choice Output\", \n",
    "    *[pl.col(\"Choice Output\").shift(i).alias(f\"lagged_{i}_choice_ago\") for i in [1,2,3,4]]\n",
    "    )\n",
    "    lagged_df_everything_stats = lagged_df_everything_stats.drop_nulls()\n",
    "    \n",
    "    lagged_df_everything_stats.write_csv(mouse_id+'_newest_lagged_mm_everything_stats.csv')\n",
    "    return lagged_df_everything_stats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "336bf858-8bd1-447a-8a47-65459943b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def added_time_means(lagged_df_everything_stats, mouse_id):\n",
    "    f = lagged_df_everything_stats.drop(columns = ['Choice Output', 'lagged_1_choice_ago', 'lagged_2_choice_ago','lagged_3_choice_ago', \n",
    "                                                   'lagged_4_choice_ago']);\n",
    "    r_arm_mean2s = []\n",
    "    r_arm_mean3s = []\n",
    "    r_arm_mean4s = []\n",
    "    r_arm_mean5s = []\n",
    "\n",
    "    p_arm_mean2s = []\n",
    "    p_arm_mean3s = []\n",
    "    p_arm_mean4s = []\n",
    "\n",
    "    p_mid_mean2s = []\n",
    "    p_mid_mean3s = []\n",
    "    p_mid_mean4s = []\n",
    "    p_mid_mean5s = []\n",
    "\n",
    "    r_arm_2s = []\n",
    "    r_arm_3s = []\n",
    "    r_arm_4s = []\n",
    "    r_arm_5s = []\n",
    "\n",
    "    p_arm_2s = []\n",
    "    p_arm_3s = []\n",
    "    p_arm_4s = []\n",
    "\n",
    "    p_mid_2s = []\n",
    "    p_mid_3s = []\n",
    "    p_mid_4s = []\n",
    "    p_mid_5s = []\n",
    "    \n",
    "    p_exitmid_2s = []\n",
    "    p_exitmid_3s = []\n",
    "    p_exitmid_4s = []\n",
    "    p_exitmid_5s = []\n",
    "\n",
    "    p_exitmid_mean2s = []\n",
    "    p_exitmid_mean3s = []\n",
    "    p_exitmid_mean4s = []\n",
    "    p_exitmid_mean5s = []\n",
    "\n",
    "    p_midentry_2s = []\n",
    "    p_midentry_3s = []\n",
    "    p_midentry_4s = []\n",
    "    p_midentry_5s = []\n",
    "\n",
    "    p_midentry_mean2s = []\n",
    "    p_midentry_mean3s = []\n",
    "    p_midentry_mean4s = []\n",
    "    p_midentry_mean5s = []\n",
    "    \n",
    "    p_exitmidentry_2s = []\n",
    "    p_exitmidentry_3s = []\n",
    "    p_exitmidentry_4s = []\n",
    "    p_exitmidentry_5s = []\n",
    "\n",
    "    p_exitmidentry_mean2s = []\n",
    "    p_exitmidentry_mean3s = []\n",
    "    p_exitmidentry_mean4s = []\n",
    "    p_exitmidentry_mean5s = []\n",
    "\n",
    "    \n",
    "    for i in range(0, len(lagged_df_everything_stats)):\n",
    "        r_arm_2s.append(np.sum([f['Duration'][i], f['lagged_1_duration'][i]]));\n",
    "        r_arm_3s.append(np.sum([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i]]));\n",
    "        r_arm_4s.append(np.sum([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i]]));\n",
    "        r_arm_5s.append(np.sum([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i], f['lagged_4_duration'][i]]));        \n",
    "        \n",
    "        r_arm_mean2s.append(np.average([f['Duration'][i], f['lagged_1_duration'][i]]));\n",
    "        r_arm_mean3s.append(np.average([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i]]));\n",
    "        r_arm_mean4s.append(np.average([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i]]));\n",
    "        r_arm_mean5s.append(np.average([f['Duration'][i], f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i], f['lagged_4_duration'][i]]));\n",
    "\n",
    "        p_arm_2s.append(np.sum([f['lagged_1_duration'][i], f['lagged_2_duration'][i]]));\n",
    "        p_arm_3s.append(np.sum([f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i]]));\n",
    "        p_arm_4s.append(np.sum([f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i], f['lagged_4_duration'][i]]));\n",
    "        \n",
    "        p_arm_mean2s.append(np.average([f['lagged_1_duration'][i], f['lagged_2_duration'][i]]));\n",
    "        p_arm_mean3s.append(np.average([f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i]]));\n",
    "        p_arm_mean4s.append(np.average([f['lagged_1_duration'][i], f['lagged_2_duration'][i], f['lagged_3_duration'][i], f['lagged_4_duration'][i]]));\n",
    "       \n",
    "        p_mid_2s.append(np.sum([f['Middle Duration'][i], f['lagged_1_mid_duration'][i]]));\n",
    "        p_mid_3s.append(np.sum([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i]]));\n",
    "        p_mid_4s.append(np.sum([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i], f['lagged_3_mid_duration'][i]]));\n",
    "        p_mid_5s.append(np.sum([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i], f['lagged_3_mid_duration'][i], f['lagged_4_mid_duration'][i]]));\n",
    "        \n",
    "        p_mid_mean2s.append(np.average([f['Middle Duration'][i], f['lagged_1_mid_duration'][i]]));\n",
    "        p_mid_mean3s.append(np.average([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i]]));\n",
    "        p_mid_mean4s.append(np.average([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i], f['lagged_3_mid_duration'][i]]));\n",
    "        p_mid_mean5s.append(np.average([f['Middle Duration'][i], f['lagged_1_mid_duration'][i], f['lagged_2_mid_duration'][i], f['lagged_3_mid_duration'][i], f['lagged_4_mid_duration'][i]]));\n",
    "\n",
    "        p_exitmid_2s.append(np.sum([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i]]));\n",
    "        p_exitmid_3s.append(np.sum([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i]]));\n",
    "        p_exitmid_4s.append(np.sum([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i], f['lagged_3_exitmid_duration'][i]]));\n",
    "        p_exitmid_5s.append(np.sum([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i], f['lagged_3_exitmid_duration'][i], f['lagged_4_exitmid_duration'][i]]));\n",
    "        \n",
    "        p_exitmid_mean2s.append(np.average([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i]]));\n",
    "        p_exitmid_mean3s.append(np.average([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i]]));\n",
    "        p_exitmid_mean4s.append(np.average([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i], f['lagged_3_exitmid_duration'][i]]));\n",
    "        p_exitmid_mean5s.append(np.average([f['ExitMid Duration'][i], f['lagged_1_exitmid_duration'][i], f['lagged_2_exitmid_duration'][i], f['lagged_3_exitmid_duration'][i], f['lagged_4_exitmid_duration'][i]]));\n",
    "\n",
    "        p_midentry_2s.append(np.sum([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i]]));\n",
    "        p_midentry_3s.append(np.sum([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i]]));\n",
    "        p_midentry_4s.append(np.sum([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i], f['lagged_3_midentry_duration'][i]]));\n",
    "        p_midentry_5s.append(np.sum([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i], f['lagged_3_midentry_duration'][i], f['lagged_4_midentry_duration'][i]]));\n",
    "\n",
    "        p_midentry_mean2s.append(np.average([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i]]));\n",
    "        p_midentry_mean3s.append(np.average([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i]]));\n",
    "        p_midentry_mean4s.append(np.average([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i], f['lagged_3_midentry_duration'][i]]));\n",
    "        p_midentry_mean5s.append(np.average([f['MidEntry Duration'][i], f['lagged_1_midentry_duration'][i], f['lagged_2_midentry_duration'][i], f['lagged_3_midentry_duration'][i], f['lagged_4_midentry_duration'][i]]));\n",
    "        \n",
    "        p_exitmidentry_2s.append(np.sum([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_3s.append(np.sum([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_4s.append(np.sum([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i], f['lagged_3_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_5s.append(np.sum([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i], f['lagged_3_exitmidentry_duration'][i], f['lagged_4_exitmidentry_duration'][i]]));\n",
    "        \n",
    "        p_exitmidentry_mean2s.append(np.average([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_mean3s.append(np.average([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_mean4s.append(np.average([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i], f['lagged_3_exitmidentry_duration'][i]]));\n",
    "        p_exitmidentry_mean5s.append(np.average([f['ExitMidEntry Duration'][i], f['lagged_1_exitmidentry_duration'][i], f['lagged_2_exitmidentry_duration'][i], f['lagged_3_exitmidentry_duration'][i], f['lagged_4_exitmidentry_duration'][i]]));\n",
    "               \n",
    "\n",
    "    \n",
    "    f['2_cur_arm_duration'] = r_arm_2s;\n",
    "    f['3_cur_arm_duration'] = r_arm_3s;\n",
    "    f['4_cur_arm_duration'] = r_arm_4s;\n",
    "    f['5_cur_arm_duration'] = r_arm_5s;        \n",
    "\n",
    "    f['mean_2_cur_arm_duration'] = r_arm_mean2s;\n",
    "    f['mean_3_cur_arm_duration'] = r_arm_mean3s;\n",
    "    f['mean_4_cur_arm_duration'] = r_arm_mean4s;\n",
    "    f['mean_5_cur_arm_duration'] = r_arm_mean5s;\n",
    "\n",
    "    f['2_past_arm_duration'] = p_arm_2s;\n",
    "    f['3_past_arm_duration'] = p_arm_3s;\n",
    "    f['4_past_arm_duration'] = p_arm_4s;\n",
    "    \n",
    "    f['mean_2_past_arm_duration'] = p_arm_mean2s;\n",
    "    f['mean_3_past_arm_duration'] = p_arm_mean3s;\n",
    "    f['mean_4_past_arm_duration'] = p_arm_mean4s;\n",
    "\n",
    "    f['2_past_mid_duration'] = p_mid_2s;\n",
    "    f['3_past_mid_duration'] = p_mid_3s;\n",
    "    f['4_past_mid_duration'] = p_mid_4s;\n",
    "    f['5_past_mid_duration'] = p_mid_5s;\n",
    "    \n",
    "    f['mean_2_past_mid_duration'] = p_mid_mean2s;\n",
    "    f['mean_3_past_mid_duration'] = p_mid_mean3s;\n",
    "    f['mean_4_past_mid_duration'] = p_mid_mean4s;\n",
    "    f['mean_5_past_mid_duration'] = p_mid_mean5s;\n",
    "\n",
    "\n",
    "    f['2_past_exitmid_duration'] = p_exitmid_2s;\n",
    "    f['3_past_exitmid_duration'] = p_exitmid_3s;\n",
    "    f['4_past_exitmid_duration'] = p_exitmid_4s;\n",
    "    f['5_past_exitmid_duration'] = p_exitmid_5s;\n",
    "    \n",
    "    f['mean_2_past_exitmid_duration'] = p_exitmid_mean2s;\n",
    "    f['mean_3_past_exitmid_duration'] = p_exitmid_mean3s;\n",
    "    f['mean_4_past_exitmid_duration'] = p_exitmid_mean4s;\n",
    "    f['mean_5_past_exitmid_duration'] = p_exitmid_mean5s;\n",
    "\n",
    "    f['2_past_midentry_duration'] = p_midentry_2s;\n",
    "    f['3_past_midentry_duration'] = p_midentry_3s;\n",
    "    f['4_past_midentry_duration'] = p_midentry_4s;\n",
    "    f['5_past_midentry_duration'] = p_midentry_5s;\n",
    "    \n",
    "    f['mean_2_past_midentry_duration'] = p_midentry_mean2s;\n",
    "    f['mean_3_past_midentry_duration'] = p_midentry_mean3s;\n",
    "    f['mean_4_past_midentry_duration'] = p_midentry_mean4s;\n",
    "    f['mean_5_past_midentry_duration'] = p_midentry_mean5s;\n",
    "\n",
    "    f['2_past_exitmidentry_duration'] = p_exitmidentry_2s;\n",
    "    f['3_past_exitmidentry_duration'] = p_exitmidentry_3s;\n",
    "    f['4_past_exitmidentry_duration'] = p_exitmidentry_4s;\n",
    "    f['5_past_exitmidentry_duration'] = p_exitmidentry_5s;\n",
    "    \n",
    "    f['mean_2_past_exitmidentry_duration'] = p_exitmidentry_mean2s;\n",
    "    f['mean_3_past_exitmidentry_duration'] = p_exitmidentry_mean3s;\n",
    "    f['mean_4_past_exitmidentry_duration'] = p_exitmidentry_mean4s;\n",
    "    f['mean_5_past_exitmidentry_duration'] = p_exitmidentry_mean5s;\n",
    "\n",
    "    f['Choice Output'] = lagged_df_everything_stats['Choice Output']\n",
    "    f['lagged_1_choice_ago'] = lagged_df_everything_stats['lagged_1_choice_ago']\n",
    "    f['lagged_2_choice_ago'] = lagged_df_everything_stats['lagged_2_choice_ago']\n",
    "    f['lagged_3_choice_ago'] = lagged_df_everything_stats['lagged_3_choice_ago']\n",
    "    f['lagged_4_choice_ago'] = lagged_df_everything_stats['lagged_4_choice_ago']\n",
    "\n",
    "    \n",
    "    df_lagged_added_stats = pd.DataFrame(f);\n",
    "    df_lagged_added_stats = df_lagged_added_stats.reset_index(drop=True);\n",
    "    df_lagged_added_stats.to_csv(mouse_id+'_newest_lagged_added_stats.csv');\n",
    "    return df_lagged_added_stats;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578b47b2-bf5d-4b22-8f18-b2514d9ab766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b12f52-9a91-47fc-bcc2-060f7dd37fc7",
   "metadata": {},
   "source": [
    "# All Functions organized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62c7f231-a678-42ef-b9ad-e7d9f61ce046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_boolean_sa325m1 = pd.read_csv('sa325m1_boolean.csv')\n",
    "df_mouse_boolean_sa325m2 = pd.read_csv('sa325m2_boolean.csv')\n",
    "df_mouse_boolean_sa325m3 = pd.read_csv('sa325m3_boolean.csv')\n",
    "df_mouse_boolean_sa325m4 = pd.read_csv('sa325m4_boolean.csv')\n",
    "df_mouse_boolean_sa498m2 = pd.read_csv('sa498m2_boolean.csv')\n",
    "df_mouse_boolean_sa498m3 = pd.read_csv('sa498m3_boolean.csv')\n",
    "df_mouse_boolean_sa499m1 = pd.read_csv('sa499m1_boolean.csv')\n",
    "df_mouse_boolean_sa499m2 = pd.read_csv('sa499m2_boolean.csv')\n",
    "df_mouse_boolean_sa499m3 = pd.read_csv('sa499m3_boolean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70317941-4bf9-44e1-95a8-371c623cc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_features_sa325m1 = pd.read_csv('sa325m1_features.csv')\n",
    "df_mouse_features_sa325m2 = pd.read_csv('sa325m2_features.csv')\n",
    "df_mouse_features_sa325m3 = pd.read_csv('sa325m3_features.csv')\n",
    "df_mouse_features_sa325m4 = pd.read_csv('sa325m4_features.csv')\n",
    "df_mouse_features_sa498m2 = pd.read_csv('sa498m2_features.csv')\n",
    "df_mouse_features_sa498m3 = pd.read_csv('sa498m3_features.csv')\n",
    "df_mouse_features_sa499m1 = pd.read_csv('sa499m1_features.csv')\n",
    "df_mouse_features_sa499m2 = pd.read_csv('sa499m2_features.csv')\n",
    "df_mouse_features_sa499m3 = pd.read_csv('sa499m3_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28372a43-f38f-4adf-adf1-12f20b678ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mouse_dist_roi_sa325m1 = pd.read_csv('sa325m1_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa325m2 = pd.read_csv('sa325m2_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa325m3 = pd.read_csv('sa325m3_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa325m4 = pd.read_csv('sa325m4_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa498m2 = pd.read_csv('sa498m2_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa498m3 = pd.read_csv('sa498m3_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa499m1 = pd.read_csv('sa499m1_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa499m2 = pd.read_csv('sa499m2_dist_roi.csv')\n",
    "df_mouse_dist_roi_sa499m3 = pd.read_csv('sa499m3_dist_roi.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7924ba8d-d1dd-4468-8e19-631bdb4b0a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_entries_sa325m1, df_sorted_entries_sa325m1 = valid_entries_stats(df_mouse_boolean_sa325m1, df_mouse_dist_roi_sa325m1, 'sa325m1_new')\n",
    "df_entries_sa325m2, df_sorted_entries_sa325m2 = valid_entries_stats(df_mouse_boolean_sa325m2, df_mouse_dist_roi_sa325m2, 'sa325m2_new')\n",
    "df_entries_sa325m3, df_sorted_entries_sa325m3 = valid_entries_stats(df_mouse_boolean_sa325m3, df_mouse_dist_roi_sa325m3, 'sa325m3_new')\n",
    "df_entries_sa325m4, df_sorted_entries_sa325m4 = valid_entries_stats(df_mouse_boolean_sa325m4, df_mouse_dist_roi_sa325m4, 'sa325m4_new')\n",
    "df_entries_sa498m2, df_sorted_entries_sa498m2 = valid_entries_stats(df_mouse_boolean_sa498m2, df_mouse_dist_roi_sa498m2, 'sa498m2_new')\n",
    "df_entries_sa498m3, df_sorted_entries_sa498m3 = valid_entries_stats(df_mouse_boolean_sa498m3, df_mouse_dist_roi_sa498m3, 'sa498m3_new')\n",
    "df_entries_sa499m1, df_sorted_entries_sa499m1 = valid_entries_stats(df_mouse_boolean_sa499m1, df_mouse_dist_roi_sa499m1, 'sa499m1_new')\n",
    "df_entries_sa499m2, df_sorted_entries_sa499m2 = valid_entries_stats(df_mouse_boolean_sa499m2, df_mouse_dist_roi_sa499m2, 'sa499m2_new')\n",
    "df_entries_sa499m3, df_sorted_entries_sa499m3 = valid_entries_stats(df_mouse_boolean_sa499m3, df_mouse_dist_roi_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ead1f7b-5e89-43de-a666-c617580d3a56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_other_stats_sa325m1 = all_other_stats(df_sorted_entries_sa325m1, df_mouse_features_sa325m1, 'sa325m1_new', 0.99045)\n",
    "df_other_stats_sa325m2 = all_other_stats(df_sorted_entries_sa325m2, df_mouse_features_sa325m2, 'sa325m2_new',0.99045)\n",
    "df_other_stats_sa325m3 = all_other_stats(df_sorted_entries_sa325m3, df_mouse_features_sa325m3, 'sa325m3_new',0.99045)\n",
    "df_other_stats_sa325m4 = all_other_stats(df_sorted_entries_sa325m4, df_mouse_features_sa325m4, 'sa325m4_new',0.99045)\n",
    "df_other_stats_sa498m2 = all_other_stats(df_sorted_entries_sa498m2, df_mouse_features_sa498m2, 'sa498m2_new',0.99045)\n",
    "df_other_stats_sa498m3 = all_other_stats(df_sorted_entries_sa498m3, df_mouse_features_sa498m3, 'sa498m3_new',0.99045)\n",
    "df_other_stats_sa499m1 = all_other_stats(df_sorted_entries_sa499m1, df_mouse_features_sa499m1, 'sa499m1_new',0.99045)\n",
    "df_other_stats_sa499m2 = all_other_stats(df_sorted_entries_sa499m2, df_mouse_features_sa499m2, 'sa499m2_new',0.99045)\n",
    "df_other_stats_sa499m3 = all_other_stats(df_sorted_entries_sa499m3, df_mouse_features_sa499m3, 'sa499m3_new',0.99045)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a0f780b7-2cea-49a8-8dca-8e5d495a2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged_coeff_sa325m1 = add_lag_dir_coefficients(df_other_stats_sa325m1, df_sorted_entries_sa325m1, 'sa325m1_new')\n",
    "df_lagged_coeff_sa325m2 = add_lag_dir_coefficients(df_other_stats_sa325m2, df_sorted_entries_sa325m2, 'sa325m2_new')\n",
    "df_lagged_coeff_sa325m3 = add_lag_dir_coefficients(df_other_stats_sa325m3, df_sorted_entries_sa325m3, 'sa325m3_new')\n",
    "df_lagged_coeff_sa325m4 = add_lag_dir_coefficients(df_other_stats_sa325m4, df_sorted_entries_sa325m4, 'sa325m4_new')\n",
    "df_lagged_coeff_sa498m2 = add_lag_dir_coefficients(df_other_stats_sa498m2, df_sorted_entries_sa498m2, 'sa498m2_new')\n",
    "df_lagged_coeff_sa498m3 = add_lag_dir_coefficients(df_other_stats_sa498m3, df_sorted_entries_sa498m3, 'sa498m3_new')\n",
    "df_lagged_coeff_sa499m1 = add_lag_dir_coefficients(df_other_stats_sa499m1, df_sorted_entries_sa499m1, 'sa499m1_new')\n",
    "df_lagged_coeff_sa499m2 = add_lag_dir_coefficients(df_other_stats_sa499m2, df_sorted_entries_sa499m2, 'sa499m2_new')\n",
    "df_lagged_coeff_sa499m3 = add_lag_dir_coefficients(df_other_stats_sa499m3, df_sorted_entries_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7592f42-d949-4c21-bf88-dcd23791b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_everything_stats_sa325m1 = add_choice_output(df_sorted_entries_sa325m1, df_other_stats_sa325m1, df_lagged_coeff_sa325m1, 'sa325m1_new')\n",
    "df_everything_stats_sa325m2 = add_choice_output(df_sorted_entries_sa325m2, df_other_stats_sa325m2, df_lagged_coeff_sa325m2, 'sa325m2_new')\n",
    "df_everything_stats_sa325m3 = add_choice_output(df_sorted_entries_sa325m3, df_other_stats_sa325m3, df_lagged_coeff_sa325m3, 'sa325m3_new')\n",
    "df_everything_stats_sa325m4 = add_choice_output(df_sorted_entries_sa325m4, df_other_stats_sa325m4, df_lagged_coeff_sa325m4, 'sa325m4_new')\n",
    "df_everything_stats_sa498m2 = add_choice_output(df_sorted_entries_sa498m2, df_other_stats_sa498m2, df_lagged_coeff_sa498m2, 'sa498m2_new')\n",
    "df_everything_stats_sa498m3 = add_choice_output(df_sorted_entries_sa498m3, df_other_stats_sa498m3, df_lagged_coeff_sa498m3, 'sa498m3_new')\n",
    "df_everything_stats_sa499m1 = add_choice_output(df_sorted_entries_sa499m1, df_other_stats_sa499m1, df_lagged_coeff_sa499m1, 'sa499m1_new')\n",
    "df_everything_stats_sa499m2 = add_choice_output(df_sorted_entries_sa499m2, df_other_stats_sa499m2, df_lagged_coeff_sa499m2, 'sa499m2_new')\n",
    "df_everything_stats_sa499m3 = add_choice_output(df_sorted_entries_sa499m3, df_other_stats_sa499m3, df_lagged_coeff_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03c62567-99cf-449e-a439-091f67abfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_everything_stats_sa325m1 = scale_it(df_everything_stats_sa325m1, 'sa325m1_new')\n",
    "mm_everything_stats_sa325m2 = scale_it(df_everything_stats_sa325m2, 'sa325m2_new')\n",
    "mm_everything_stats_sa325m3 = scale_it(df_everything_stats_sa325m3, 'sa325m3_new')\n",
    "mm_everything_stats_sa325m4 = scale_it(df_everything_stats_sa325m4, 'sa325m4_new')\n",
    "mm_everything_stats_sa498m2 = scale_it(df_everything_stats_sa498m2, 'sa498m2_new')\n",
    "mm_everything_stats_sa498m3 = scale_it(df_everything_stats_sa498m3, 'sa498m3_new')\n",
    "mm_everything_stats_sa499m1 = scale_it(df_everything_stats_sa499m1, 'sa499m1_new')\n",
    "mm_everything_stats_sa499m2 = scale_it(df_everything_stats_sa499m2, 'sa499m2_new')\n",
    "mm_everything_stats_sa499m3 = scale_it(df_everything_stats_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "697ceaee-c27c-47c5-a158-433f9d1119d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_pls_sa325m1 = pl.read_csv('sa325m1_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa325m2 = pl.read_csv('sa325m2_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa325m3 = pl.read_csv('sa325m3_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa325m4 = pl.read_csv('sa325m4_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa498m2 = pl.read_csv('sa498m2_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa498m3 = pl.read_csv('sa498m3_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa499m1 = pl.read_csv('sa499m1_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa499m2 = pl.read_csv('sa499m2_new_newest_mm_everything_stats.csv')\n",
    "mm_pls_sa499m3 = pl.read_csv('sa499m3_new_newest_mm_everything_stats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dbea245-5c53-44a0-b5e9-f82358fe0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_mm_everything_stats_sa325m1 = lagging_four_prev_choices(mm_pls_sa325m1, 'sa325m1_new')\n",
    "lagged_mm_everything_stats_sa325m2 = lagging_four_prev_choices(mm_pls_sa325m2, 'sa325m2_new')\n",
    "lagged_mm_everything_stats_sa325m3 = lagging_four_prev_choices(mm_pls_sa325m3, 'sa325m3_new')\n",
    "lagged_mm_everything_stats_sa325m4 = lagging_four_prev_choices(mm_pls_sa325m4, 'sa325m4_new')\n",
    "lagged_mm_everything_stats_sa498m2 = lagging_four_prev_choices(mm_pls_sa498m2, 'sa498m2_new')\n",
    "lagged_mm_everything_stats_sa498m3 = lagging_four_prev_choices(mm_pls_sa498m3, 'sa498m3_new')\n",
    "lagged_mm_everything_stats_sa499m1 = lagging_four_prev_choices(mm_pls_sa499m1, 'sa499m1_new')\n",
    "lagged_mm_everything_stats_sa499m2 = lagging_four_prev_choices(mm_pls_sa499m2, 'sa499m2_new')\n",
    "lagged_mm_everything_stats_sa499m3  = lagging_four_prev_choices(mm_pls_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bd52ee1-b836-45f8-b64b-e1a54b41e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged_mm_everything_stats_sa325m1 = pd.read_csv('sa325m1_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa325m2 = pd.read_csv('sa325m2_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa325m3 = pd.read_csv('sa325m3_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa325m4 = pd.read_csv('sa325m4_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa498m2 = pd.read_csv('sa498m2_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa498m3 = pd.read_csv('sa498m3_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa499m1 = pd.read_csv('sa499m1_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa499m2 = pd.read_csv('sa499m2_new_newest_lagged_mm_everything_stats.csv')\n",
    "df_lagged_mm_everything_stats_sa499m3 = pd.read_csv('sa499m3_new_newest_lagged_mm_everything_stats.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6325c28-c519-4d4d-b836-86c663457aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lagged_added_stats_sa325m1 = added_time_means(df_lagged_mm_everything_stats_sa325m1, 'sa325m1_new')\n",
    "df_lagged_added_stats_sa325m2 = added_time_means(df_lagged_mm_everything_stats_sa325m2, 'sa325m2_new')\n",
    "df_lagged_added_stats_sa325m3 = added_time_means(df_lagged_mm_everything_stats_sa325m3, 'sa325m3_new')\n",
    "df_lagged_added_stats_sa325m4 = added_time_means(df_lagged_mm_everything_stats_sa325m4, 'sa325m4_new')\n",
    "df_lagged_added_stats_sa498m2 = added_time_means(df_lagged_mm_everything_stats_sa498m2, 'sa498m2_new')\n",
    "df_lagged_added_stats_sa498m3 = added_time_means(df_lagged_mm_everything_stats_sa498m3, 'sa498m3_new')\n",
    "df_lagged_added_stats_sa499m1 = added_time_means(df_lagged_mm_everything_stats_sa499m1, 'sa499m1_new')\n",
    "df_lagged_added_stats_sa499m2 = added_time_means(df_lagged_mm_everything_stats_sa499m2, 'sa499m2_new')\n",
    "df_lagged_added_stats_sa499m3 = added_time_means(df_lagged_mm_everything_stats_sa499m3, 'sa499m3_new')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0767b93-e2e7-4581-b75e-c0291d86c7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa325m1\n",
    "sa325m2\n",
    "sa325m3\n",
    "sa325m4\n",
    "sa498m2\n",
    "sa498m3\n",
    "sa499m1\n",
    "sa499m2\n",
    "sa499m3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2956889a-15ad-4e8e-a5c4-a9a99b6b2f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d703e-480c-4171-a905-bce527c20ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700b5f5b-4ce1-46de-9288-5802a7042ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaf2f7d-ab08-4bae-bf34-39f27c6a47a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb647d-9bd9-4466-af44-7364417b01c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d40b82-c19a-4eee-b4c2-94fbe5e93d41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b0c9e-5439-4936-92c5-29110e3f7ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ddb634-f648-4efa-b1ae-69df7b505859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9430a6a9-a580-4359-9a80-417778105f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
